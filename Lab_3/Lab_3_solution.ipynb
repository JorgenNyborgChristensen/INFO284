{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frozen-progress",
   "metadata": {},
   "source": [
    "### Lab week 6 (Feb 8th – Feb 12th)\n",
    "\n",
    "One issue in natural language processing is the identification of sentiment of texts, are they positive,\n",
    "negative or neutral to some concept. This dataset\n",
    "(https://github.com/thanhtut/info284_lab/blob/master/assignment1/twitter-airlinesentiment/Tweets.csv) has a collection of tweets about airlines with corresponding sentiments\n",
    "(negative, positive, neutral).\n",
    "\n",
    "The task we want you to do is to run three machine learning models using Naïve Bayes on the tweet\n",
    "texts.\n",
    "1. Prepare the data for machine learning. Extract the relevant columns, do language\n",
    "preprocessing of the tweets, etc.\n",
    "2. Run a BernoulliNB to classify sentiment\n",
    "3. Run a MultiomialNB to classify sentiment\n",
    "4. Run a MultinomialNB to classify sentiment, but instead of using a count vector you should\n",
    "use a TF-IDF-vector for each instance. \n",
    "\n",
    "What is TF-IDF? Read sources on information retrieval,\n",
    "and also look here: https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "\n",
    "How do the three approaches compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-desktop",
   "metadata": {},
   "source": [
    "## Working with text data in scikit-learn\n",
    " https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "## Exploratory data analysis\n",
    "https://www.kaggle.com/parthsharma5795/comprehensive-twitter-airline-sentiment-analysis\n",
    "\n",
    "## Data analysis and data cleaning\n",
    "https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greatest-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stone-importance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optimum-gates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe is (14640, 15)\n",
      "The number of nulls in each column are \n",
      " tweet_id                            0\n",
      "airline_sentiment                   0\n",
      "airline_sentiment_confidence        0\n",
      "negativereason                   5462\n",
      "negativereason_confidence        4118\n",
      "airline                             0\n",
      "airline_sentiment_gold          14600\n",
      "name                                0\n",
      "negativereason_gold             14608\n",
      "retweet_count                       0\n",
      "text                                0\n",
      "tweet_coord                     13621\n",
      "tweet_created                       0\n",
      "tweet_location                   4733\n",
      "user_timezone                    4820\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataframe is\",df.shape)\n",
    "print(\"The number of nulls in each column are \\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "announced-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extreme-saudi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "Name: negativereason, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negativereason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interested-credit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-revelation",
   "metadata": {},
   "source": [
    "### 1. Prepare the data for machine learning. Extract the relevant columns, do language preprocessing of the tweets, etc.\n",
    "Clean text data: https://stackabuse.com/text-classification-with-python-and-scikit-learn/\n",
    "\n",
    "Preprocessing using CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Train test split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-scanning",
   "metadata": {},
   "source": [
    "#### 1) Clean text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-silver",
   "metadata": {},
   "source": [
    "If you don't have nltk or emoji installed, run: \n",
    "\n",
    "!pip install emoji\n",
    "\n",
    "!pip install nltk\n",
    "\n",
    "in an empty cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "animated-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negativereason'] = df['negativereason'].fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "premium-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jorge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "\n",
    "df['text'] = df['text'].map(lambda x: cleaner(x))\n",
    "df['negativereason'] = df['negativereason'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-seeking",
   "metadata": {},
   "source": [
    "#### 2) Apply CountVectorizer to the text data\n",
    "Read more about min_df and max_df parameters here: https://stackoverflow.com/questions/27697766/understanding-min-df-and-max-df-in-scikit-countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "global-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X= vectorizer.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-cooperative",
   "metadata": {},
   "source": [
    "#### 3) Select target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "clean-quilt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1    positive\n",
       "2     neutral\n",
       "3    negative\n",
       "4    negative\n",
       "Name: airline_sentiment, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['airline_sentiment']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-explosion",
   "metadata": {},
   "source": [
    "#### 4) Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "wound-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-underground",
   "metadata": {},
   "source": [
    "### 2. Run a BernoulliNB to classify sentiment\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-recipient",
   "metadata": {},
   "source": [
    "#### 1) Import BernoulliNB and fit to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "macro-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-greeting",
   "metadata": {},
   "source": [
    "#### 2) Return predicted target values for X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "psychological-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-village",
   "metadata": {},
   "source": [
    "#### 3) Get test set score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "moral-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7691256830601093"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-giving",
   "metadata": {},
   "source": [
    "#### 4) Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "hundred-proportion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85      1889\n",
      "     neutral       0.55      0.61      0.58       580\n",
      "    positive       0.70      0.67      0.68       459\n",
      "\n",
      "    accuracy                           0.77      2928\n",
      "   macro avg       0.70      0.71      0.70      2928\n",
      "weighted avg       0.78      0.77      0.77      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wicked-democrat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    1889\n",
      "neutral      580\n",
      "positive     459\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x29210b59388>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Number of classes in our test set\n",
    "print(y_test.value_counts())\n",
    "\n",
    "plot_confusion_matrix(clf, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-technical",
   "metadata": {},
   "source": [
    "The diagonal (1593, 353, 306) shows the number of tweets our model was able to correctly predict. The first row shows that we correctly classified 1593 tweets as being negative, and incorreclty classified 219 to be neutral and 77 to be negative. The second row shows that our model correclty classified 353 tweets as neutral, 171 neutral as being negative and 56 as being positive. The third row shows that we correclty classified 306 tweets as being positive, incorreclty classified 74 positive tweets as being neutral and 79 as negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-soundtrack",
   "metadata": {},
   "source": [
    "### 3. Run a MultiomialNB to classify sentiment\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "extended-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "younger-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bacterial-aircraft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7517076502732241"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "asian-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.88      0.84      1889\n",
      "     neutral       0.54      0.42      0.48       580\n",
      "    positive       0.70      0.65      0.67       459\n",
      "\n",
      "    accuracy                           0.75      2928\n",
      "   macro avg       0.68      0.65      0.66      2928\n",
      "weighted avg       0.74      0.75      0.74      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-discussion",
   "metadata": {},
   "source": [
    "### 4. Run a MultinomialNB to classify sentiment, but instead of using a count vector you should use a TF-IDF-vector for each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "existing-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = tfidfconverter.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "leading-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "suburban-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "genuine-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "timely-google",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7459016393442623"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "northern-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.97      0.84      1889\n",
      "     neutral       0.69      0.25      0.37       580\n",
      "    positive       0.83      0.44      0.58       459\n",
      "\n",
      "    accuracy                           0.75      2928\n",
      "   macro avg       0.75      0.56      0.60      2928\n",
      "weighted avg       0.74      0.75      0.71      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
